%!TEX root = paper_ecg_cs_codec.tex
\section{Introduction}
\label{sec:intro}
In wireless body area networks (WBAN)
based telemonitoring networks\cite{cao2009enabling},
the energy consumption on sensor nodes is
a primary design constraint \cite{milenkovic2006wireless}.
The wearable sensor nodes are often battery-operated.
It is necessary to reduce energy consumption as
much as possible.
It is desirable that a low-complexity encoder
is used for the compression of ECG data from wearable
devices.
Compressive sensing (CS) \cite{donoho2006compressed,baraniuk2007compressive,
candes2006compressive, candes2008introduction, candes2006near}
provides a very good solution to implement low-complexity encoders
and has been extensively studied for ECG data
compression \cite{craven2014compressed,kumar2022review}.
It uses a sub-Nyquist sampling method by acquiring a small number
of incoherent measurements which are sufficient to reconstruct
the signal if the signal is sufficiently sparse in some
basis.
For a sparse signal $\bx \in \RR^n$, one would make
$m$ linear measurements where $m \ll n$ which can be
mathematically represented by a sensing operation
\begin{equation}
\by = \Phi \bx
\end{equation}
where $\Phi \in \RR^{m \times n}$ is a matrix
representation of the sensing process and $\by \in \RR^m$
the set of $m$ measurements collected for $\bx$.
A suitable reconstruction algorithm can recover $\bx$
from $\by$.

Ideally, the sensing process should be implemented at the
hardware level in the analog-to-digital conversion (ADC) process.
However, much of the use of CS in ECG follows
a digital CS paradigm \cite{mamaghanian2011compressed} where
the ECG samples are acquired first by the ADC circuit on the
device and then they are translated into incoherent
measurements via the multiplication of a digital sensing matrix.
These measurements are then transmitted
to remote telemonitoring servers.
A suitable reconstruction algorithm is used on the server
to recover the original ECG signal from the compressive measurements.
Reconstruction algorithms for ECG signals include:
greedy algorithms 
\cite{polania2011compressed} (simultaneous orthogonal matching pursuit),
optimization-based algorithms \cite{zhang2014energy},
\cite{mamaghanian2011compressed} (SPG-L1),
Bayesian learning algorithms
\cite{zhang2012compressed,zhang2014spatiotemporal,zhang2013extension},
and deep learning based algorithms \cite{zhang2021csnet}.

We consider the problem of efficient transmission of
compressive measurements of ECG signals over the wireless body
area networks under the digital compressive sensing paradigm.
Let $\bx$ be an ECG signal and $\by$ be the corresponding
stream of compressive measurements. Our goal is to
transform $\by$ into a bitstream $\bs$ with as few bits
as possible without losing the signal reconstruction quality.

A primary constraint in our design is that the encoder
should avoid any floating point arithmetic.


\subsection{Related Work}

The literature on the use of CS for ECG compression is mostly
focused on the design of a specific \emph{sensing matrix},
\emph{sparsifying dictionary}, or \emph{reconstruction algorithm}
for the high-quality reconstruction of the ECG signal from the
compressive measurements.
To the best of our knowledge, (digital) quantization and entropy coding of
the compressive measurements of ECG data haven't received much attention
in the literature.

Mamaghanian et al.\cite{mamaghanian2011compressed} use a Huffman codebook
which is deployed inside the sensor device. They don't
employ any quantization of the measurements.
The codebook is fixed. It cannot adapt to differing signal
statistics.

Simulation-based studies generally send the floating point compressive
measurements to their decoder modules.
They don't consider the issue of
the number of bits required to encode each measurement.
The compression ratio is often defined simply as $\frac{m}{n}$
or some variant of it
\footnote{Other variants include
$\frac{n}{m}$ \cite{zhang2012compressed},
$\frac{n-m}{n} \times 100$ \cite{zhang2021csnet}}.
The underlying assumption is that the measurements are
encoded using the same number of bits as the original digital samples.

Huffman codes have frequently been used in ECG data
compression for non-CS methods \cite{luo2014dynamic,chouakri2013wavelet}
for entropy coding.
However, entropy coding of CS measurements has largely been ignored.

Asymmetric Numeral Systems (ANS) \cite{duda2013asymmetric}
based entropy coding schemes have seen much success
in recent years for lossless data compression.
They provide superior compression compared to Huffman
like symbol codes.
To the best of our knowledge, ANS stream codes
have not been considered in the past for the entropy
coding of compressive measurements.


\subsection{Contributions}
In this paper, we present an adaptive quantization and
entropy coding scheme for digital compressive measurements.
The adaptive quantization scheme has been designed
to ensure bounded quantization noise.
A quantized Gaussian probability model of the measurements
is estimated directly from the data
and the parameters for this model are used
for the entropy coding of the measurements.  
Asymmetric numeral systems (ANS) based
entropy coding is then used for efficient entropy coding
of the quantized and clipped measurements.
Our encoding scheme doesn't require a fixed codebook
for entropy coding.
The encoder can be implemented entirely using integer arithmetic.
Our implementation is available as part of
reproducible research on GitHub \cite{kumar2022ecgcodec}.

\subsection{Paper Organization}
The rest of the paper is organized as follows.
\Cref{sec:arch} describes our proposed codec architecture.
\Cref{sec:data} describes the ECG database
used for the evaluation of the codec and the
performance metrics.
The analysis of the experimental results is covered in \cref{sec:results}.
\Cref{sec:conclusion} summarizes our contributions and major findings.

